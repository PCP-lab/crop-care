{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cc3ce6",
   "metadata": {},
   "source": [
    "\n",
    "# Weather Feature Pipeline (Open‑Meteo) — Leaf Spot Risk (Hydrangea)\n",
    "\n",
    "This notebook fetches **past 60 days** of hourly/daily weather from **Open‑Meteo** for a given location and photo time, then computes derived features useful for **leaf spot disease risk** (Cercospora/Septoria/Anthracnose).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631b1e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/myid/bp67339/myenv/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: pandas in /home/myid/bp67339/myenv/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: python-dateutil in /home/myid/bp67339/myenv/lib/python3.10/site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/myid/bp67339/myenv/lib/python3.10/site-packages (from python-dateutil) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 0. Requirements ===\n",
    "# If running for the first time, uncomment:\n",
    "!pip install requests pandas python-dateutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b76c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1. Parameters (to be passed from frontend or edited here) ===\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Example values; your frontend should pass these\n",
    "PHOTO_TIMESTAMP_UTC = \"2025-09-10T14:05:00Z\"   # ISO string from EXIF or user\n",
    "LAT = 33.948    # Athens, GA\n",
    "LON = -83.377\n",
    "DAYS_BACK = 60   # Open-Meteo supports longer history, but 60 days is good for v1\n",
    "\n",
    "# If you only want to compute risk up to the day BEFORE the photo:\n",
    "USE_WINDOW_END_ON_DAY_MINUS_1 = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9689315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query window: 2025-07-12 → 2025-09-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                     temperature_2m  relative_humidity_2m  precipitation  \\\n",
       " time                                                                       \n",
       " 2025-07-12 00:00:00            27.0                    82            0.0   \n",
       " 2025-07-12 01:00:00            25.6                    85            0.0   \n",
       " 2025-07-12 02:00:00            25.2                    86            0.0   \n",
       " 2025-07-12 03:00:00            24.5                    89            0.0   \n",
       " 2025-07-12 04:00:00            24.1                    91            0.0   \n",
       " \n",
       "                      cloudcover  shortwave_radiation  \n",
       " time                                                  \n",
       " 2025-07-12 00:00:00          86                103.0  \n",
       " 2025-07-12 01:00:00         100                 18.0  \n",
       " 2025-07-12 02:00:00          28                  0.0  \n",
       " 2025-07-12 03:00:00          57                  0.0  \n",
       " 2025-07-12 04:00:00          83                  0.0  ,\n",
       "             temperature_2m_max  temperature_2m_min  precipitation_sum  \\\n",
       " time                                                                    \n",
       " 2025-07-12                31.6                22.5                1.4   \n",
       " 2025-07-13                33.0                23.2                0.1   \n",
       " 2025-07-14                34.5                23.2                0.0   \n",
       " 2025-07-15                33.6                22.9                0.0   \n",
       " 2025-07-16                32.0                23.2                1.0   \n",
       " \n",
       "             et0_fao_evapotranspiration  \n",
       " time                                    \n",
       " 2025-07-12                        5.25  \n",
       " 2025-07-13                        5.73  \n",
       " 2025-07-14                        5.98  \n",
       " 2025-07-15                        5.36  \n",
       " 2025-07-16                        5.30  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 2. Fetch Open-Meteo data (hourly + daily) ===\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def date_range_for_photo(photo_iso: str, days_back: int = 60, day_minus_1: bool = True):\n",
    "    dt = datetime.fromisoformat(photo_iso.replace(\"Z\",\"\")).replace(tzinfo=timezone.utc).date()\n",
    "    end = (dt - timedelta(days=1)) if day_minus_1 else dt\n",
    "    start = end - timedelta(days=days_back-1)\n",
    "    return start.isoformat(), end.isoformat()\n",
    "\n",
    "def fetch_open_meteo(lat: float, lon: float, start_date: str, end_date: str, timezone_str=\"UTC\"):\n",
    "    # Hourly variables for derived features\n",
    "    hourly_vars = [\n",
    "        \"temperature_2m\",\n",
    "        \"relative_humidity_2m\",\n",
    "        \"precipitation\",\n",
    "        \"cloudcover\",\n",
    "        \"shortwave_radiation\"\n",
    "    ]\n",
    "    # Daily variables (some are optional depending on archive)\n",
    "    daily_vars = [\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"precipitation_sum\",\n",
    "        \"et0_fao_evapotranspiration\"  # may be missing depending on product; handled gracefully\n",
    "    ]\n",
    "\n",
    "    base = \"https://archive-api.open-meteo.com/v1/era5\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"timezone\": timezone_str,\n",
    "        \"hourly\": \",\".join(hourly_vars),\n",
    "        \"daily\": \",\".join(daily_vars)\n",
    "    }\n",
    "    r = requests.get(base, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data\n",
    "\n",
    "start_date, end_date = date_range_for_photo(PHOTO_TIMESTAMP_UTC, DAYS_BACK, USE_WINDOW_END_ON_DAY_MINUS_1)\n",
    "print(\"Query window:\", start_date, \"→\", end_date)\n",
    "\n",
    "data = fetch_open_meteo(LAT, LON, start_date, end_date, \"UTC\")\n",
    "\n",
    "# Parse hourly\n",
    "h = data.get(\"hourly\", {})\n",
    "if not h:\n",
    "    raise RuntimeError(\"No hourly data returned from Open-Meteo.\")\n",
    "hourly_df = pd.DataFrame(h)\n",
    "hourly_df[\"time\"] = pd.to_datetime(hourly_df[\"time\"])\n",
    "hourly_df = hourly_df.set_index(\"time\").sort_index()\n",
    "\n",
    "# Parse daily\n",
    "d = data.get(\"daily\", {})\n",
    "daily_df = pd.DataFrame(d)\n",
    "daily_df[\"time\"] = pd.to_datetime(daily_df[\"time\"])\n",
    "daily_df = daily_df.set_index(\"time\").sort_index()\n",
    "\n",
    "hourly_df.head(), daily_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3419dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 3. Derived metrics & helper functions ===\n",
    "import math\n",
    "\n",
    "def vpd_kpa(T_c, RH):\n",
    "    es = 0.6108 * math.exp((17.27*T_c)/(T_c+237.3))\n",
    "    ea = es * (RH/100.0)\n",
    "    return max(0.0, es - ea)\n",
    "\n",
    "def dew_point_c(T_c, RH):\n",
    "    # Magnus approximation\n",
    "    a, b = 17.27, 237.3\n",
    "    RHc = max(1e-6, RH/100.0)\n",
    "    gamma = (a*T_c)/(b+T_c) + math.log(RHc)\n",
    "    return (b*gamma)/(a - gamma)\n",
    "\n",
    "def compute_leaf_wetness_hours(hourly):\n",
    "    # Proxy: hours with RH>=90 OR (T - Td)<=2°C\n",
    "    count = 0\n",
    "    for t, row in hourly.iterrows():\n",
    "        T = float(row[\"temperature_2m\"])\n",
    "        RH = float(row[\"relative_humidity_2m\"])\n",
    "        Td = dew_point_c(T, RH)\n",
    "        if (RH >= 90) or (T - Td <= 2.0):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def gdd_base_day(tmin, tmax, base=10.0):\n",
    "    return max(0.0, ((tmin + tmax)/2.0) - base)\n",
    "\n",
    "def rolling_features(hourly_df, daily_df, end_date):\n",
    "    # Compute last 7 and 14 day windows ending at end_date (inclusive)\n",
    "    d_end = pd.to_datetime(end_date)\n",
    "    d7_start  = d_end - pd.Timedelta(days=6)\n",
    "    d14_start = d_end - pd.Timedelta(days=13)\n",
    "    \n",
    "    # Slice daily\n",
    "    d7  = daily_df.loc[d7_start:d_end]\n",
    "    d14 = daily_df.loc[d14_start:d_end]\n",
    "\n",
    "    # Slice hourly\n",
    "    h7  = hourly_df.loc[d7_start:d_end + pd.Timedelta(days=1) - pd.Timedelta(hours=1)]\n",
    "    h14 = hourly_df.loc[d14_start:d_end + pd.Timedelta(days=1) - pd.Timedelta(hours=1)]\n",
    "\n",
    "    # Temperature\n",
    "    T_mean_7 = (d7[\"temperature_2m_max\"] + d7[\"temperature_2m_min\"]).mean()/2.0 if len(d7) else float(\"nan\")\n",
    "    T_min_7  = d7[\"temperature_2m_min\"].min() if len(d7) else float(\"nan\")\n",
    "    T_max_7  = d7[\"temperature_2m_max\"].max() if len(d7) else float(\"nan\")\n",
    "\n",
    "    # Humidity\n",
    "    RH_mean_7 = h7[\"relative_humidity_2m\"].mean() if len(h7) else float(\"nan\")\n",
    "    RH_max_7  = h7[\"relative_humidity_2m\"].max() if len(h7) else float(\"nan\")\n",
    "\n",
    "    # Rain\n",
    "    Rain_sum_7  = d7[\"precipitation_sum\"].sum() if \"precipitation_sum\" in d7 else float(\"nan\")\n",
    "    Rain_days_7 = (d7[\"precipitation_sum\"] >= 1.0).sum() if \"precipitation_sum\" in d7 else 0\n",
    "    # Rain hours from hourly precip > 0\n",
    "    Rain_hours_7 = (h7[\"precipitation\"] > 0).sum() if \"precipitation\" in h7 else 0\n",
    "\n",
    "    # Leaf wetness proxy\n",
    "    RH_hours_ge90_7 = (h7[\"relative_humidity_2m\"] >= 90).sum() if \"relative_humidity_2m\" in h7 else 0\n",
    "    LWD_hours_7 = compute_leaf_wetness_hours(h7) if len(h7) else 0\n",
    "\n",
    "    # VPD\n",
    "    VPD_mean_7 = h7.apply(lambda r: vpd_kpa(r[\"temperature_2m\"], r[\"relative_humidity_2m\"]), axis=1).mean() if len(h7) else float(\"nan\")\n",
    "    VPD_max_7  = h7.apply(lambda r: vpd_kpa(r[\"temperature_2m\"], r[\"relative_humidity_2m\"]), axis=1).max()  if len(h7) else float(\"nan\")\n",
    "\n",
    "    # GDD base 10C over last 14 days\n",
    "    if len(d14):\n",
    "        GDD_10_14 = sum(gdd_base_day(a,b,base=10.0) for a,b in zip(d14[\"temperature_2m_min\"], d14[\"temperature_2m_max\"]))\n",
    "    else:\n",
    "        GDD_10_14 = float(\"nan\")\n",
    "\n",
    "    # Humid streak (days with mean RH>=85)\n",
    "    # We need daily mean RH; approximate from hourly by daily groupby\n",
    "    daily_rh_mean = h14[\"relative_humidity_2m\"].groupby(h14.index.date).mean() if len(h14) else pd.Series(dtype=float)\n",
    "    max_streak = 0; cur = 0\n",
    "    for val in daily_rh_mean.values:\n",
    "        if val >= 85:\n",
    "            cur += 1\n",
    "            max_streak = max(max_streak, cur)\n",
    "        else:\n",
    "            cur = 0\n",
    "\n",
    "    return {\n",
    "        \"window_end_date\": str(d_end.date()),\n",
    "        \"T_mean_7\": T_mean_7, \"T_min_7\": T_min_7, \"T_max_7\": T_max_7,\n",
    "        \"RH_mean_7\": RH_mean_7, \"RH_max_7\": RH_max_7,\n",
    "        \"Rain_sum_7\": Rain_sum_7, \"Rain_days_7\": int(Rain_days_7), \"Rain_hours_7\": int(Rain_hours_7),\n",
    "        \"RH_hours_ge90_7\": int(RH_hours_ge90_7), \"LWD_hours_7\": int(LWD_hours_7),\n",
    "        \"VPD_mean_7\": VPD_mean_7, \"VPD_max_7\": VPD_max_7,\n",
    "        \"GDD_10_14\": GDD_10_14,\n",
    "        \"Humid_streak_10\": int(max_streak)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f4b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived weather features (ending on) 2025-09-09\n",
      "T_mean_7: 22.82857142857143\n",
      "T_min_7: 15.0\n",
      "T_max_7: 31.1\n",
      "RH_mean_7: 73.17857142857143\n",
      "RH_max_7: 98\n",
      "Rain_sum_7: 17.400000000000002\n",
      "Rain_days_7: 3\n",
      "Rain_hours_7: 21\n",
      "RH_hours_ge90_7: 31\n",
      "LWD_hours_7: 34\n",
      "VPD_mean_7: 0.7891651315429797\n",
      "VPD_max_7: 2.259116191701851\n",
      "GDD_10_14: 174.9\n",
      "Humid_streak_10: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 4. Compute and print features for the last 7–14 days window ===\n",
    "features = rolling_features(hourly_df, daily_df, end_date)\n",
    "print(\"Derived weather features (ending on)\", features[\"window_end_date\"])\n",
    "for k, v in features.items():\n",
    "    if k != \"window_end_date\":\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c710f67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2025-09-09'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ranked, feats, prior, hourly_df, daily_df\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# --- Example call (Athens, GA; use your KB path below) ---\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m ranked, feats, prior, hdf, ddf \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_disease_from_location_date\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/myid/bp67339/plant_disease/data/kb_leaf_spots.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m33.948\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m83.377\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2025-09-10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# the user/photo date\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_days_back\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_day_minus_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTop-1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ranked[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeatures used (key subset):\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m       {k: feats[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT_mean_7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRH_hours_ge90_7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLWD_hours_7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRain_sum_7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVPD_mean_7\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m feats})\n",
      "Cell \u001b[0;32mIn[10], line 51\u001b[0m, in \u001b[0;36mpredict_disease_from_location_date\u001b[0;34m(kb_path, lat, lon, date_str, window_days, fetch_days_back, use_day_minus_1, timezone_str, floor, topk)\u001b[0m\n\u001b[1;32m     48\u001b[0m disease_universe \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m kb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiseases\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 6) Score KB → prior vector → rank\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m prior \u001b[38;5;241m=\u001b[39m \u001b[43mweather_prior_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease_universe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mprior)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# 7) Print results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m, in \u001b[0;36mweather_prior_vector\u001b[0;34m(kb, feats, disease_universe, floor)\u001b[0m\n\u001b[1;32m     43\u001b[0m         out[i] \u001b[38;5;241m=\u001b[39m floor\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(floor, \u001b[38;5;28mfloat\u001b[39m(\u001b[43mscore_weather_for_disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     46\u001b[0m out \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (out\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-12\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mscore_weather_for_disease\u001b[0;34m(d_entry, feats)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m d_entry\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscoring\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrules\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n\u001b[1;32m     30\u001b[0m     cond, add \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m))\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_rule_true\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     32\u001b[0m         sc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add\n\u001b[1;32m     33\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(d_entry\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscoring\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1.0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36m_rule_true\u001b[0;34m(expr, feats)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feats\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 21\u001b[0m     s \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m), s)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28meval\u001b[39m(s, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__builtins__\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}}, {}))\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2025-09-09'"
     ]
    }
   ],
   "source": [
    "# === Predict directly from (lat, lon, date) using your KB ===\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def predict_disease_from_location_date(\n",
    "    kb_path: str,\n",
    "    lat: float,\n",
    "    lon: float,\n",
    "    date_str: str,                  # e.g., \"2025-08-15\"\n",
    "    window_days: int = 7,           # look-back window for features (your KB rules use 7d)\n",
    "    fetch_days_back: int = 21,      # how much data to fetch (>=14 because we compute some 14d feats)\n",
    "    use_day_minus_1: bool = True,   # end the window on day-1 relative to the photo date\n",
    "    timezone_str: str = \"UTC\",\n",
    "    floor: float = 0.05,\n",
    "    topk: int = 10\n",
    "):\n",
    "    # 1) Decide fetch range around the chosen date\n",
    "    #    We fetch a bit more than needed so rolling_features can compute 7d & 14d windows robustly.\n",
    "    dt = datetime.fromisoformat(date_str)\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=timezone.utc)\n",
    "    end_day = (dt.date() - timedelta(days=1)) if use_day_minus_1 else dt.date()\n",
    "    start_day = end_day - timedelta(days=fetch_days_back-1)\n",
    "\n",
    "    # 2) Fetch Open-Meteo (hourly + daily)\n",
    "    data = fetch_open_meteo(lat, lon, start_day.isoformat(), end_day.isoformat(), timezone_str)\n",
    "\n",
    "    # 3) Parse hourly/daily into DataFrames\n",
    "    h = data.get(\"hourly\", {})\n",
    "    if not h:\n",
    "        raise RuntimeError(\"No hourly data returned from Open-Meteo.\")\n",
    "    hourly_df = pd.DataFrame(h)\n",
    "    hourly_df[\"time\"] = pd.to_datetime(hourly_df[\"time\"])\n",
    "    hourly_df = hourly_df.set_index(\"time\").sort_index()\n",
    "\n",
    "    d = data.get(\"daily\", {})\n",
    "    daily_df = pd.DataFrame(d)\n",
    "    daily_df[\"time\"] = pd.to_datetime(daily_df[\"time\"])\n",
    "    daily_df = daily_df.set_index(\"time\").sort_index()\n",
    "\n",
    "    # 4) Compute rolling features ending at end_day\n",
    "    feats = rolling_features(hourly_df, daily_df, end_day)\n",
    "\n",
    "    # 5) Load KB and define disease order (using KB names; swap to labels.json if fusing with text model)\n",
    "    kb = load_weather_kb(kb_path)\n",
    "    disease_universe = [d[\"name\"] for d in kb[\"diseases\"]]\n",
    "\n",
    "    # 6) Score KB → prior vector → rank\n",
    "    prior = weather_prior_vector(kb, feats, disease_universe, floor=floor)\n",
    "    order = np.argsort(-prior)\n",
    "\n",
    "    # 7) Print results\n",
    "    print(f\"\\n=== KB-based prediction for {end_day} at (lat={lat:.4f}, lon={lon:.4f}) \"\n",
    "          f\"[window: last {window_days} days; end_on_day_minus_1={use_day_minus_1}] ===\")\n",
    "    for i in order[:topk]:\n",
    "        print(f\"{disease_universe[i]:35s}  prior={prior[i]:.3f}\")\n",
    "\n",
    "    # 8) Return handy objects\n",
    "    ranked = [(disease_universe[i], float(prior[i])) for i in order]\n",
    "    return ranked, feats, prior, hourly_df, daily_df\n",
    "\n",
    "# --- Example call (Athens, GA; use your KB path below) ---\n",
    "ranked, feats, prior, hdf, ddf = predict_disease_from_location_date(\n",
    "    kb_path=\"/home/myid/bp67339/plant_disease/data/kb_leaf_spots.json\",\n",
    "    lat=33.948, lon=-83.377,\n",
    "    date_str=\"2025-09-10\",   # the user/photo date\n",
    "    window_days=7,\n",
    "    fetch_days_back=21,\n",
    "    use_day_minus_1=True,\n",
    "    floor=0.05,\n",
    "    topk=10\n",
    ")\n",
    "\n",
    "print(\"\\nTop-1:\", ranked[0])\n",
    "print(\"\\nFeatures used (key subset):\",\n",
    "      {k: feats[k] for k in [\"T_mean_7\",\"RH_hours_ge90_7\",\"LWD_hours_7\",\"Rain_sum_7\",\"VPD_mean_7\"] if k in feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b121912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KB-based prediction for 2025-09-16 at (lat=33.9480, lon=-83.3770) [window: last 7 days; end_on_day_minus_1=True] ===\n",
      "Spot Anthracnose (Dogwood)           prior=0.167\n",
      "Phyllosticta Leaf Spot (ornamental shrubs incl. Hydrangea)  prior=0.167\n",
      "Bacterial Leaf Spot (Hydrangea)      prior=0.143\n",
      "Septoria Leaf Spot                   prior=0.143\n",
      "Bacterial Leaf Scorch (physiological look-alike)  prior=0.143\n",
      "Cercospora Leaf Spot                 prior=0.119\n",
      "Anthracnose (leaf spot/blight on Hydrangea)  prior=0.119\n",
      "\n",
      "Top-1: ('Spot Anthracnose (Dogwood)', 0.16666666666658728)\n",
      "\n",
      "Feature snapshot: {'T_mean_7': 21.866666666666664, 'RH_hours_ge90_7': 5, 'LWD_hours_7': 8, 'Rain_sum_7': 0.30000000000000004, 'VPD_mean_7': 0.8416018131723381}\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Weather → KB: end-to-end scorer\n",
    "# ===============================\n",
    "import json, re, math, requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pandas.api.types import is_datetime64_any_dtype, is_datetime64tz_dtype\n",
    "\n",
    "# ---------- Open-Meteo fetch ----------\n",
    "def fetch_open_meteo(lat: float, lon: float, start_date: str, end_date: str, timezone_str=\"UTC\") -> Dict[str, Any]:\n",
    "    hourly_vars = [\n",
    "        \"temperature_2m\",\n",
    "        \"relative_humidity_2m\",\n",
    "        \"precipitation\",\n",
    "        \"cloudcover\",\n",
    "        \"shortwave_radiation\",\n",
    "    ]\n",
    "    daily_vars = [\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"precipitation_sum\",\n",
    "        \"et0_fao_evapotranspiration\",\n",
    "    ]\n",
    "    base = \"https://archive-api.open-meteo.com/v1/era5\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"timezone\": timezone_str,\n",
    "        \"hourly\": \",\".join(hourly_vars),\n",
    "        \"daily\": \",\".join(daily_vars),\n",
    "    }\n",
    "    r = requests.get(base, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "# ---------- KB helpers (hardened) ----------\n",
    "_ALLOWED = set(list(\"0123456789.+-*/()<>=! &|\") + list(\"_\") +\n",
    "               list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "\n",
    "def load_weather_kb(fp: str) -> Dict[str, Any]:\n",
    "    with open(fp, \"r\") as f:\n",
    "        kb = json.load(f)\n",
    "    by_name = {re.sub(r\"\\s+\",\" \",d[\"name\"].strip().lower()): d for d in kb[\"diseases\"]}\n",
    "    kb[\"_by_name\"] = by_name\n",
    "    return kb\n",
    "\n",
    "def _rule_true(expr: str, feats: Dict[str, Any]) -> bool:\n",
    "    \"\"\"Evaluate a boolean rule expression safely, substituting only numeric features.\"\"\"\n",
    "    s = expr.replace(\"&&\", \" and \").replace(\"||\", \" or \")\n",
    "    if any(ch not in _ALLOWED for ch in s):\n",
    "        return False\n",
    "    for k, v in feats.items():\n",
    "        # substitute only numeric values\n",
    "        try:\n",
    "            fv = float(v)\n",
    "        except (TypeError, ValueError):\n",
    "            continue\n",
    "        s = re.sub(rf\"\\b{k}\\b\", str(fv), s)\n",
    "    try:\n",
    "        return bool(eval(s, {\"__builtins__\": {}}, {}))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def score_weather_for_disease(d_entry: Dict[str, Any], feats: Dict[str, Any]) -> float:\n",
    "    \"\"\"Sum rule contributions and cap; feats can contain non-numeric keys safely.\"\"\"\n",
    "    sc = 0.0\n",
    "    for r in d_entry.get(\"scoring\", {}).get(\"rules\", []):\n",
    "        cond, add = r.get(\"if\", \"\"), float(r.get(\"add\", 0.0))\n",
    "        if cond and _rule_true(cond, feats):\n",
    "            sc += add\n",
    "    cap = float(d_entry.get(\"scoring\", {}).get(\"cap\", 1.0))\n",
    "    return max(0.0, min(cap, sc))\n",
    "\n",
    "def weather_prior_vector(kb: Dict[str, Any],\n",
    "                         feats: Dict[str, Any],\n",
    "                         disease_universe: List[str],\n",
    "                         floor: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"Always sanitizes features internally; returns normalized prior over diseases.\"\"\"\n",
    "    out = np.zeros(len(disease_universe), dtype=np.float64)\n",
    "    for i, name in enumerate(disease_universe):\n",
    "        key = re.sub(r\"\\s+\",\" \",name.strip().lower())\n",
    "        d_entry = kb[\"_by_name\"].get(key)\n",
    "        if d_entry is None:\n",
    "            out[i] = floor\n",
    "        else:\n",
    "            out[i] = max(floor, float(score_weather_for_disease(d_entry, feats)))\n",
    "    out /= (out.sum() + 1e-12)\n",
    "    return out\n",
    "\n",
    "# ---------- Feature engineering ----------\n",
    "def vpd_kpa(T_c: float, RH: float) -> float:\n",
    "    es = 0.6108 * math.exp((17.27*T_c)/(T_c+237.3))\n",
    "    ea = es * (max(0.0, min(100.0, RH))/100.0)\n",
    "    return max(0.0, es - ea)\n",
    "\n",
    "def dew_point_c(T_c: float, RH: float) -> float:\n",
    "    a, b = 17.27, 237.3\n",
    "    RHc = max(1e-6, min(1.0, RH/100.0))\n",
    "    gamma = (a*T_c)/(b+T_c) + math.log(RHc)\n",
    "    return (b*gamma)/(a - gamma)\n",
    "\n",
    "def compute_leaf_wetness_hours(hourly: pd.DataFrame) -> int:\n",
    "    # Proxy: RH>=90 OR (T - Td)<=2°C\n",
    "    if hourly.empty:\n",
    "        return 0\n",
    "    Td = hourly.apply(lambda r: dew_point_c(r[\"temperature_2m\"], r[\"relative_humidity_2m\"]), axis=1)\n",
    "    return int(((hourly[\"relative_humidity_2m\"] >= 90) | ((hourly[\"temperature_2m\"] - Td) <= 2.0)).sum())\n",
    "\n",
    "def _to_utc(ts):\n",
    "    ts = pd.to_datetime(ts)\n",
    "    if ts.tzinfo is None:\n",
    "        return ts.tz_localize(\"UTC\")\n",
    "    return ts.tz_convert(\"UTC\")\n",
    "\n",
    "def rolling_features(hourly_df: pd.DataFrame, daily_df: pd.DataFrame, end_date) -> Dict[str, Any]:\n",
    "    \"\"\"Compute 7d/14d features ending on end_date (inclusive), with UTC-aware bounds.\"\"\"\n",
    "    # Make end-of-day UTC (tz-aware)\n",
    "    d_end = _to_utc(end_date).normalize()  # midnight UTC of that day\n",
    "\n",
    "    d7_start  = d_end - pd.Timedelta(days=6)\n",
    "    d14_start = d_end - pd.Timedelta(days=13)\n",
    "\n",
    "    # Ensure UTC datetime indexes\n",
    "    if not (isinstance(hourly_df.index, pd.DatetimeIndex) and hourly_df.index.tz is not None):\n",
    "        hf = hourly_df.copy()\n",
    "        if \"time\" in hf.columns:\n",
    "            hf[\"time\"] = pd.to_datetime(hf[\"time\"], utc=True)\n",
    "            hourly_df = hf.set_index(\"time\").sort_index()\n",
    "        else:\n",
    "            raise ValueError(\"hourly_df must have a tz-aware DatetimeIndex or a 'time' column.\")\n",
    "\n",
    "    if not (isinstance(daily_df.index, pd.DatetimeIndex) and daily_df.index.tz is not None):\n",
    "        df = daily_df.copy()\n",
    "        if \"time\" in df.columns:\n",
    "            df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True)\n",
    "            daily_df = df.set_index(\"time\").sort_index()\n",
    "        else:\n",
    "            raise ValueError(\"daily_df must have a tz-aware DatetimeIndex or a 'time' column.\")\n",
    "\n",
    "    # Slices (inclusive day window)\n",
    "    d7  = daily_df.loc[(daily_df.index >= d7_start) & (daily_df.index <= d_end)]\n",
    "    d14 = daily_df.loc[(daily_df.index >= d14_start) & (daily_df.index <= d_end)]\n",
    "\n",
    "    h7  = hourly_df.loc[(hourly_df.index >= d7_start)  & (hourly_df.index <= d_end + pd.Timedelta(hours=23))]\n",
    "    h14 = hourly_df.loc[(hourly_df.index >= d14_start) & (hourly_df.index <= d_end + pd.Timedelta(hours=23))]\n",
    "\n",
    "    # ---- metrics (same as before) ----\n",
    "    T_mean_7 = float(((d7[\"temperature_2m_max\"] + d7[\"temperature_2m_min\"]) / 2.0).mean()) if len(d7) else float(\"nan\")\n",
    "    T_min_7  = float(d7[\"temperature_2m_min\"].min()) if len(d7) else float(\"nan\")\n",
    "    T_max_7  = float(d7[\"temperature_2m_max\"].max()) if len(d7) else float(\"nan\")\n",
    "\n",
    "    RH_mean_7 = float(h7[\"relative_humidity_2m\"].mean()) if len(h7) else float(\"nan\")\n",
    "    RH_max_7  = float(h7[\"relative_humidity_2m\"].max())  if len(h7) else float(\"nan\")\n",
    "\n",
    "    Rain_sum_7  = float(d7[\"precipitation_sum\"].sum()) if \"precipitation_sum\" in d7 else float(\"nan\")\n",
    "    Rain_days_7 = int((d7[\"precipitation_sum\"] >= 1.0).sum()) if \"precipitation_sum\" in d7 else 0\n",
    "    Rain_hours_7 = int((h7[\"precipitation\"] > 0).sum()) if \"precipitation\" in h7 else 0\n",
    "\n",
    "    RH_hours_ge90_7 = int((h7[\"relative_humidity_2m\"] >= 90).sum()) if \"relative_humidity_2m\" in h7 else 0\n",
    "    LWD_hours_7 = compute_leaf_wetness_hours(h7) if len(h7) else 0\n",
    "\n",
    "    if len(h7):\n",
    "        vpd_series = h7.apply(lambda r: vpd_kpa(r[\"temperature_2m\"], r[\"relative_humidity_2m\"]), axis=1)\n",
    "        VPD_mean_7 = float(vpd_series.mean())\n",
    "        VPD_max_7  = float(vpd_series.max())\n",
    "    else:\n",
    "        VPD_mean_7 = float(\"nan\"); VPD_max_7 = float(\"nan\")\n",
    "\n",
    "    if len(h14):\n",
    "        daily_rh_mean = h14[\"relative_humidity_2m\"].groupby(h14.index.date).mean()\n",
    "        max_streak = 0; cur = 0\n",
    "        for val in daily_rh_mean.values:\n",
    "            if val >= 85:\n",
    "                cur += 1; max_streak = max(max_streak, cur)\n",
    "            else:\n",
    "                cur = 0\n",
    "    else:\n",
    "        max_streak = 0\n",
    "\n",
    "    return {\n",
    "        \"window_end_date\": str(d_end.date()),\n",
    "        \"T_mean_7\": T_mean_7, \"T_min_7\": T_min_7, \"T_max_7\": T_max_7,\n",
    "        \"RH_mean_7\": RH_mean_7, \"RH_max_7\": RH_max_7,\n",
    "        \"Rain_sum_7\": Rain_sum_7, \"Rain_days_7\": Rain_days_7, \"Rain_hours_7\": Rain_hours_7,\n",
    "        \"RH_hours_ge90_7\": RH_hours_ge90_7, \"LWD_hours_7\": LWD_hours_7,\n",
    "        \"VPD_mean_7\": VPD_mean_7, \"VPD_max_7\": VPD_max_7,\n",
    "        \"Humid_streak_10\": int(max_streak),\n",
    "    }\n",
    "# ---------- Main prediction APIs ----------\n",
    "def predict_disease_from_location_date(\n",
    "    kb_path: str,\n",
    "    lat: float,\n",
    "    lon: float,\n",
    "    date_str: str,                 # \"YYYY-MM-DD\"\n",
    "    fetch_days_back: int = 21,     # >=14 for 14d feats\n",
    "    use_day_minus_1: bool = True,  # end window on previous day\n",
    "    timezone_str: str = \"UTC\",\n",
    "    floor: float = 0.05,\n",
    "    topk: int = 10\n",
    ") -> Tuple[List[Tuple[str, float]], Dict[str, Any], np.ndarray, pd.DataFrame, pd.DataFrame]:\n",
    "    # resolve date range\n",
    "    dt = datetime.fromisoformat(date_str)\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=timezone.utc)\n",
    "    end_day = (dt.date() - timedelta(days=1)) if use_day_minus_1 else dt.date()\n",
    "    start_day = end_day - timedelta(days=fetch_days_back-1)\n",
    "\n",
    "    # fetch weather\n",
    "    data = fetch_open_meteo(lat, lon, start_day.isoformat(), end_day.isoformat(), timezone_str)\n",
    "\n",
    "    # parse hourly/daily\n",
    "    h = data.get(\"hourly\", {})\n",
    "    if not h:\n",
    "        raise RuntimeError(\"No hourly data returned from Open-Meteo.\")\n",
    "    hourly_df = pd.DataFrame(h)\n",
    "    hourly_df[\"time\"] = pd.to_datetime(hourly_df[\"time\"], utc=True)\n",
    "    hourly_df = hourly_df.set_index(\"time\").sort_index()\n",
    "\n",
    "    d = data.get(\"daily\", {})\n",
    "    daily_df = pd.DataFrame(d)\n",
    "    daily_df[\"time\"] = pd.to_datetime(daily_df[\"time\"], utc=True)\n",
    "    daily_df = daily_df.set_index(\"time\").sort_index()\n",
    "\n",
    "    # features over last 7 days ending at end_day\n",
    "    feats = rolling_features(hourly_df, daily_df, end_day)\n",
    "\n",
    "    # KB scoring\n",
    "    kb = load_weather_kb(kb_path)\n",
    "    disease_universe = [d[\"name\"] for d in kb[\"diseases\"]]\n",
    "    prior = weather_prior_vector(kb, feats, disease_universe, floor=floor)\n",
    "    order = np.argsort(-prior)\n",
    "\n",
    "    # print\n",
    "    print(f\"\\n=== KB-based prediction for {end_day} at (lat={lat:.4f}, lon={lon:.4f}) \"\n",
    "          f\"[window: last 7 days; end_on_day_minus_1={use_day_minus_1}] ===\")\n",
    "    for i in order[:topk]:\n",
    "        print(f\"{disease_universe[i]:35s}  prior={prior[i]:.3f}\")\n",
    "\n",
    "    ranked = [(disease_universe[i], float(prior[i])) for i in order]\n",
    "    return ranked, feats, prior, hourly_df, daily_df\n",
    "\n",
    "def predict_disease_from_weather_df(\n",
    "    kb_path: str,\n",
    "    hourly_df: pd.DataFrame,\n",
    "    daily_df: pd.DataFrame,\n",
    "    end_day,                     # date or Timestamp\n",
    "    floor: float = 0.05,\n",
    "    topk: int = 10\n",
    ") -> Tuple[List[Tuple[str, float]], Dict[str, Any], np.ndarray]:\n",
    "    \"\"\"Use this if you already have local weather DataFrames.\"\"\"\n",
    "    # ensure indices are datetime and UTC\n",
    "    def _ensure_dtidx(df, colname=\"time\"):\n",
    "        if isinstance(df.index, pd.RangeIndex) or not (is_datetime64_any_dtype(df.index) or is_datetime64tz_dtype(df.index)):\n",
    "            if colname in df.columns:\n",
    "                df = df.copy()\n",
    "                df[colname] = pd.to_datetime(df[colname], utc=True)\n",
    "                df = df.set_index(colname)\n",
    "            else:\n",
    "                raise ValueError(\"DataFrame must have a datetime index or a datetime column named 'time'.\")\n",
    "        return df.sort_index()\n",
    "\n",
    "    hourly_df = _ensure_dtidx(hourly_df)\n",
    "    daily_df  = _ensure_dtidx(daily_df)\n",
    "\n",
    "    feats = rolling_features(hourly_df, daily_df, end_day)\n",
    "    kb = load_weather_kb(kb_path)\n",
    "    disease_universe = [d[\"name\"] for d in kb[\"diseases\"]]\n",
    "    prior = weather_prior_vector(kb, feats, disease_universe, floor=floor)\n",
    "    order = np.argsort(-prior)\n",
    "\n",
    "    print(f\"\\n=== KB-based prediction for {pd.to_datetime(end_day).date()} (preloaded DF) ===\")\n",
    "    for i in order[:topk]:\n",
    "        print(f\"{disease_universe[i]:35s}  prior={prior[i]:.3f}\")\n",
    "\n",
    "    ranked = [(disease_universe[i], float(prior[i])) for i in order]\n",
    "    return ranked, feats, prior\n",
    "\n",
    "\n",
    "ranked, feats, prior, hdf, ddf = predict_disease_from_location_date(\n",
    "    kb_path=\"/home/myid/bp67339/plant_disease/data/kb_leaf_spots.json\",\n",
    "    lat=33.948, lon=-83.377,\n",
    "    date_str=\"2025-09-17\",   # photo date\n",
    "    fetch_days_back=21,\n",
    "    use_day_minus_1=True,\n",
    "    floor=0.05,\n",
    "    topk=10\n",
    ")\n",
    "print(\"\\nTop-1:\", ranked[0])\n",
    "print(\"\\nFeature snapshot:\",\n",
    "      {k: feats[k] for k in [\"T_mean_7\",\"RH_hours_ge90_7\",\"LWD_hours_7\",\"Rain_sum_7\",\"VPD_mean_7\"] if k in feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd3f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All derived weather features (table) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>window_end_date</th>\n",
       "      <td>2025-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_mean_7</th>\n",
       "      <td>21.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_min_7</th>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_max_7</th>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH_mean_7</th>\n",
       "      <td>67.055172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH_max_7</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain_sum_7</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain_days_7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain_hours_7</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH_hours_ge90_7</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LWD_hours_7</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPD_mean_7</th>\n",
       "      <td>0.841602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPD_max_7</th>\n",
       "      <td>2.256261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humid_streak_10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      value\n",
       "feature                    \n",
       "window_end_date  2025-09-16\n",
       "T_mean_7          21.866667\n",
       "T_min_7                14.2\n",
       "T_max_7                28.4\n",
       "RH_mean_7         67.055172\n",
       "RH_max_7               91.0\n",
       "Rain_sum_7              0.3\n",
       "Rain_days_7               0\n",
       "Rain_hours_7              3\n",
       "RH_hours_ge90_7           5\n",
       "LWD_hours_7               8\n",
       "VPD_mean_7         0.841602\n",
       "VPD_max_7          2.256261\n",
       "Humid_streak_10           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved features to: /home/myid/bp67339/plant_disease/data/last_weather_feats.json\n"
     ]
    }
   ],
   "source": [
    "# Pretty table\n",
    "import pandas as pd, json, os\n",
    "\n",
    "feats_df = pd.DataFrame([feats]).T.rename(columns={0: \"value\"})\n",
    "feats_df.index.name = \"feature\"\n",
    "print(\"\\n=== All derived weather features (table) ===\")\n",
    "display(feats_df)  # in Jupyter shows a clean table\n",
    "\n",
    "# Optional: save for your fusion notebook\n",
    "out_fp = \"/home/myid/bp67339/plant_disease/data/last_weather_feats.json\"\n",
    "with open(out_fp, \"w\") as f:\n",
    "    json.dump(feats, f, indent=2)\n",
    "print(f\"\\nSaved features to: {out_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5355d455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            T_min (°C)  T_max (°C)  T_mean (°C)  RH_mean (%)  Rain_sum (mm)\n",
      "Date                                                                       \n",
      "2025-08-19        22.7        28.4         25.4         86.9            4.8\n",
      "2025-08-20        21.9        30.3         25.6         84.0            0.1\n",
      "2025-08-21        21.3        30.9         25.1         85.6            8.0\n",
      "2025-08-22        21.5        27.4         23.2         92.6            8.8\n",
      "2025-08-23        20.4        25.4         22.5         92.1            4.0\n",
      "2025-08-24        18.8        29.2         23.5         81.9            0.3\n",
      "2025-08-25        20.2        29.1         24.3         67.3            0.0\n",
      "2025-08-26        16.4        27.0         21.9         60.8            0.0\n",
      "2025-08-27        16.0        26.8         21.1         61.0            0.0\n",
      "2025-08-28        16.7        27.2         21.8         68.6            0.0\n",
      "2025-08-29        16.7        28.1         22.5         72.5            0.0\n",
      "2025-08-30        18.3        28.5         23.1         71.3            0.0\n",
      "2025-08-31        17.8        27.4         22.5         74.5            0.6\n",
      "2025-09-01        17.5        27.2         21.6         67.6            0.0\n",
      "2025-09-02        15.7        26.3         21.0         64.2            0.0\n",
      "2025-09-03        16.2        27.1         21.9         70.7            0.2\n",
      "2025-09-04        18.0        28.6         23.2         72.6            0.2\n",
      "2025-09-05        19.3        31.1         25.0         75.2            2.0\n",
      "2025-09-06        20.6        29.3         23.2         86.9           13.1\n",
      "2025-09-07        20.1        27.9         23.2         81.6            1.9\n",
      "2025-09-08        17.8        24.8         20.8         63.5            0.0\n",
      "2025-09-09        15.0        23.8         19.3         61.9            0.0\n",
      "2025-09-10        14.2        25.7         19.8         66.2            0.0\n",
      "2025-09-11        15.7        28.0         21.9         67.5            0.0\n",
      "2025-09-12        17.2        27.6         22.1         68.6            0.2\n",
      "2025-09-13        16.9        27.5         21.9         68.5            0.0\n",
      "2025-09-14        15.8        28.3         21.9         65.8            0.1\n",
      "2025-09-15         NaN         NaN         22.8         65.0            NaN\n",
      "2025-09-16         NaN         NaN          NaN          NaN            NaN\n",
      "2025-09-17         NaN         NaN          NaN          NaN            NaN\n",
      "\n",
      "Saved to last_30_days_weather.csv\n"
     ]
    }
   ],
   "source": [
    "# Past-1-month weather table (temp, humidity, rainfall)\n",
    "# ----------------------------------------------------\n",
    "# Requirements: requests, pandas\n",
    "# pip install requests pandas\n",
    "\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def _to_iso_date(d):\n",
    "    if isinstance(d, str):\n",
    "        return d\n",
    "    if isinstance(d, datetime):\n",
    "        return d.date().isoformat()\n",
    "    return pd.to_datetime(d).date().isoformat()\n",
    "\n",
    "def vpd_kpa(T_c: float, RH: float) -> float:\n",
    "    # Not used in the table, but handy if you want VPD later\n",
    "    es = 0.6108 * math.exp((17.27*T_c)/(T_c+237.3))\n",
    "    ea = es * (max(0.0, min(100.0, RH))/100.0)\n",
    "    return max(0.0, es - ea)\n",
    "\n",
    "def fetch_month_weather_table(\n",
    "    lat: float,\n",
    "    lon: float,\n",
    "    end_date: datetime | str | None = None,\n",
    "    days: int = 30,\n",
    "    timezone_str: str = \"UTC\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a tidy daily table for the past `days` ending at `end_date`\n",
    "    with columns: Date, T_min (°C), T_max (°C), T_mean (°C), RH_mean (%), Rain_sum (mm).\n",
    "    \"\"\"\n",
    "    # Resolve dates\n",
    "    end_dt = datetime.now(timezone.utc) if end_date is None else pd.to_datetime(end_date, utc=True).to_pydatetime()\n",
    "    end_day = end_dt.date()\n",
    "    start_day = end_day - timedelta(days=days-1)\n",
    "\n",
    "    # Open-Meteo ERA5 archive\n",
    "    base = \"https://archive-api.open-meteo.com/v1/era5\"\n",
    "    hourly_vars = [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\"]\n",
    "    daily_vars  = [\"temperature_2m_max\", \"temperature_2m_min\", \"precipitation_sum\"]\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_day.isoformat(),\n",
    "        \"end_date\": end_day.isoformat(),\n",
    "        \"timezone\": timezone_str,\n",
    "        \"hourly\": \",\".join(hourly_vars),\n",
    "        \"daily\": \",\".join(daily_vars),\n",
    "    }\n",
    "\n",
    "    r = requests.get(base, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    # Daily frame (min/max temp, daily rain)\n",
    "    d = pd.DataFrame(data.get(\"daily\", {}))\n",
    "    if d.empty:\n",
    "        raise RuntimeError(\"No daily data returned.\")\n",
    "    d[\"time\"] = pd.to_datetime(d[\"time\"])\n",
    "    d = d.set_index(\"time\").sort_index()\n",
    "\n",
    "    # Hourly to compute daily RH mean (and optional T mean)\n",
    "    h = pd.DataFrame(data.get(\"hourly\", {}))\n",
    "    if h.empty:\n",
    "        raise RuntimeError(\"No hourly data returned.\")\n",
    "    h[\"time\"] = pd.to_datetime(h[\"time\"])\n",
    "    h = h.set_index(\"time\").sort_index()\n",
    "\n",
    "    # Aggregate hourly → daily means\n",
    "    rh_daily_mean = h[\"relative_humidity_2m\"].groupby(h.index.date).mean()\n",
    "    t_daily_mean  = h[\"temperature_2m\"].groupby(h.index.date).mean()\n",
    "\n",
    "    # Assemble final table\n",
    "    out = pd.DataFrame(index=d.index)\n",
    "    out.index.name = \"Date\"\n",
    "\n",
    "    out[\"T_min (°C)\"]  = d[\"temperature_2m_min\"]\n",
    "    out[\"T_max (°C)\"]  = d[\"temperature_2m_max\"]\n",
    "    out[\"T_mean (°C)\"] = pd.Series(t_daily_mean.values, index=pd.to_datetime(rh_daily_mean.index))\n",
    "    out[\"RH_mean (%)\"] = pd.Series(rh_daily_mean.values, index=pd.to_datetime(rh_daily_mean.index))\n",
    "    out[\"Rain_sum (mm)\"] = d[\"precipitation_sum\"]\n",
    "\n",
    "    # Tidy up: round and sort columns\n",
    "    out = out[[\"T_min (°C)\", \"T_max (°C)\", \"T_mean (°C)\", \"RH_mean (%)\", \"Rain_sum (mm)\"]]\n",
    "    out = out.round({\"T_min (°C)\": 1, \"T_max (°C)\": 1, \"T_mean (°C)\": 1, \"RH_mean (%)\": 1, \"Rain_sum (mm)\": 2})\n",
    "    return out\n",
    "\n",
    "# ---- Example usage ----\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Athens, GA\n",
    "    lat, lon = 33.948, -83.377\n",
    "    table = fetch_month_weather_table(lat, lon, timezone_str=\"America/New_York\")\n",
    "\n",
    "    # Display (in notebooks, this renders nicely)\n",
    "    print(table.to_string())\n",
    "\n",
    "    # Save to CSV if you want\n",
    "    table.to_csv(\"last_30_days_weather.csv\")\n",
    "    print(\"\\nSaved to last_30_days_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d12829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-09-22 | End: 2025-10-08 | TZ: UTC\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import os, json, math, datetime as dt\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# HTTP\n",
    "import requests\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# Location & horizon\n",
    "LAT = 33.95      # <- change to your latitude\n",
    "LON = -83.37     # <- change to your longitude\n",
    "TZ  = \"UTC\"      # e.g., \"America/New_York\" if you prefer local time\n",
    "DAYS_AHEAD = 16  # Open-Meteo forecast horizon (max ~16 days)\n",
    "\n",
    "# Date window: today -> today+DAYS_AHEAD\n",
    "today = dt.date.today()\n",
    "start_date = today.isoformat()\n",
    "end_date   = (today + dt.timedelta(days=DAYS_AHEAD)).isoformat()\n",
    "\n",
    "print(\"Start:\", start_date, \"| End:\", end_date, \"| TZ:\", TZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3689b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick only what you need. You can add/remove variables from:\n",
    "# https://open-meteo.com/ (Docs → Forecast API variables)\n",
    "\n",
    "hourly_vars = [\n",
    "    \"temperature_2m\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"precipitation\",\n",
    "    \"cloudcover\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_gusts_10m\",\n",
    "]\n",
    "\n",
    "daily_vars = [\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"precipitation_sum\",\n",
    "    \"sunrise\",\n",
    "    \"sunset\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b75178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_open_meteo_forecast(\n",
    "    lat, lon, timezone_str, hourly, daily, forecast_days=16, timeout=30\n",
    "):\n",
    "    base = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"timezone\": timezone_str,\n",
    "        \"forecast_days\": int(forecast_days),   # <= use this\n",
    "        \"past_days\": 0,                        # (optional) ensure only future\n",
    "        \"hourly\": \",\".join(hourly) if hourly else None,\n",
    "        \"daily\": \",\".join(daily) if daily else None,\n",
    "    }\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "    r = requests.get(base, params=params, timeout=timeout)\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        # Helpful debug\n",
    "        raise RuntimeError(f\"Open-Meteo error {r.status_code}: {r.text}\") from e\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994f011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hourly Forecast (first 24 hours) ===\n",
      "                     temperature_2m  relative_humidity_2m  precipitation  cloudcover  wind_speed_10m  wind_gusts_10m\n",
      "time                                                                                                                \n",
      "2025-09-22 00:00:00            23.0                    80            0.0           6             5.6            10.8\n",
      "2025-09-22 01:00:00            21.4                    88            0.0           0             6.1            10.8\n",
      "2025-09-22 02:00:00            20.5                    85            0.0          50             1.8            12.2\n",
      "2025-09-22 03:00:00            20.0                    88            0.0          11             3.2             5.0\n",
      "2025-09-22 04:00:00            19.9                    89            0.0          13             3.3             5.8\n",
      "2025-09-22 05:00:00            19.5                    84            0.0           3             7.9            20.2\n",
      "2025-09-22 06:00:00            19.0                    90            0.0           3             6.8            18.7\n",
      "2025-09-22 07:00:00            18.4                    89            0.0           1             3.4             9.0\n",
      "2025-09-22 08:00:00            18.2                    88            0.0           0             3.8             7.9\n",
      "2025-09-22 09:00:00            17.9                    91            0.0           1             4.4            10.1\n",
      "2025-09-22 10:00:00            17.7                    93            0.0           3             2.6             7.2\n",
      "2025-09-22 11:00:00            17.6                    92            0.0           4             5.2             6.8\n",
      "2025-09-22 12:00:00            18.0                    96            0.0           5             4.2             6.8\n",
      "2025-09-22 13:00:00            19.9                    97            0.0          50             5.1            11.9\n",
      "2025-09-22 14:00:00            22.6                    87            0.0          50             2.3            12.2\n",
      "2025-09-22 15:00:00            24.1                    86            0.0          21             6.5            11.5\n",
      "2025-09-22 16:00:00            25.9                    68            0.0          26             5.5             6.8\n",
      "2025-09-22 17:00:00            27.0                    60            0.0          24             7.3             9.4\n",
      "2025-09-22 18:00:00            28.3                    51            0.0          13             8.3             9.7\n",
      "2025-09-22 19:00:00            29.2                    44            0.0           9             8.6             9.7\n",
      "2025-09-22 20:00:00            29.6                    39            0.0           0            10.3            11.9\n",
      "2025-09-22 21:00:00            29.5                    39            0.0           0             8.7            11.2\n",
      "2025-09-22 22:00:00            29.2                    38            0.0           1             6.2             9.0\n",
      "2025-09-22 23:00:00            27.7                    41            0.0           0             7.4            11.5\n",
      "\n",
      "=== Daily Forecast (full 16 days) ===\n",
      "            temperature_2m_max  temperature_2m_min  precipitation_sum           sunrise            sunset\n",
      "time                                                                                                     \n",
      "2025-09-22                29.6                17.6                0.0  2025-09-22T11:22  2025-09-22T23:30\n",
      "2025-09-23                32.1                17.8                0.0  2025-09-23T11:22  2025-09-23T23:28\n",
      "2025-09-24                34.5                19.1                0.0  2025-09-24T11:23  2025-09-24T23:27\n",
      "2025-09-25                32.6                20.0                0.5  2025-09-25T11:24  2025-09-25T23:25\n",
      "2025-09-26                23.5                20.5                9.5  2025-09-26T11:24  2025-09-26T23:24\n",
      "2025-09-27                28.7                18.4                7.3  2025-09-27T11:25  2025-09-27T23:23\n",
      "2025-09-28                27.5                18.0                2.0  2025-09-28T11:26  2025-09-28T23:21\n",
      "2025-09-29                25.8                19.4                2.5  2025-09-29T11:26  2025-09-29T23:20\n",
      "2025-09-30                30.1                17.9                0.3  2025-09-30T11:27  2025-09-30T23:19\n",
      "2025-10-01                22.3                17.4                0.0  2025-10-01T11:28  2025-10-01T23:17\n",
      "2025-10-02                20.6                16.2                0.0  2025-10-02T11:29  2025-10-02T23:16\n",
      "2025-10-03                22.9                14.5                0.0  2025-10-03T11:29  2025-10-03T23:14\n",
      "2025-10-04                19.9                13.0                0.9  2025-10-04T11:30  2025-10-04T23:13\n",
      "2025-10-05                15.5                14.2                0.3  2025-10-05T11:31  2025-10-05T23:12\n",
      "2025-10-06                26.7                15.3                0.0  2025-10-06T11:32  2025-10-06T23:10\n",
      "2025-10-07                24.8                14.1                0.0  2025-10-07T11:32  2025-10-07T23:09\n"
     ]
    }
   ],
   "source": [
    "raw = fetch_open_meteo_forecast(\n",
    "    LAT, LON, TZ, hourly=hourly_vars, daily=daily_vars, forecast_days=16\n",
    ")\n",
    "\n",
    "# Hourly table\n",
    "hourly = pd.DataFrame(raw.get(\"hourly\", {}))\n",
    "if not hourly.empty:\n",
    "    hourly[\"time\"] = pd.to_datetime(hourly[\"time\"])\n",
    "    hourly = hourly.set_index(\"time\").sort_index()\n",
    "\n",
    "# Daily table\n",
    "daily = pd.DataFrame(raw.get(\"daily\", {}))\n",
    "if not daily.empty:\n",
    "    daily[\"time\"] = pd.to_datetime(daily[\"time\"])\n",
    "    daily = daily.set_index(\"time\").sort_index()\n",
    "\n",
    "print(\"=== Hourly Forecast (first 24 hours) ===\")\n",
    "print(hourly.head(24))\n",
    "\n",
    "print(\"\\n=== Daily Forecast (full 16 days) ===\")\n",
    "print(daily)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
